#!/usr/bin/env python3
"""
Azure Role Assignment Exporter (ARA)
====================================

A professional tool for exporting Azure role assignments at management group
and subscription scopes with comprehensive reporting and multiple output formats.

Features:
- Multiple authentication methods (environment, Azure CLI, keychain, interactive)
- Hierarchical management group scanning
- Principal name resolution via Microsoft Graph API
- JSON, CSV, and Excel output formats
- Direct assignment filtering (excludes inherited)
- Robust error handling and logging
- Production-ready with proper OOP design

Requirements:
- Python 3.7+
- Azure credentials with appropriate permissions
- Read access to role assignments and management groups

Author: fjdev
License: MIT
Version: 1.0.0
"""

# Standard library imports
import argparse
import asyncio
import base64
import csv
import functools
import json
import logging
import os
import re
import signal
import subprocess
import sys
import time
import urllib.error
import urllib.parse
import urllib.request
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, List, Optional, Any

__version__ = "2.0.0"
__author__ = "fjdev"


class ARAConfig:
    """Configuration constants for ARA."""
    # API Endpoints
    AZURE_MANAGEMENT_URL = "https://management.azure.com"
    GRAPH_API_URL = "https://graph.microsoft.com/v1.0"
    
    # API versions
    AZURE_API_VERSION = "2020-01-01"
    AUTH_API_VERSION = "2022-04-01"
    MGMT_GROUP_API_VERSION = "2020-05-01"
    
    # Timeouts
    API_REQUEST_TIMEOUT = 30  # seconds
    TOKEN_VALIDATION_TIMEOUT = 10  # seconds
    
    # Performance
    MAX_CONCURRENT_REQUESTS = 5
    CACHE_SIZE_LIMIT = 1000
    
    # File Handling
    RESULTS_DIR = "results"
    JSON_INDENT = 2
    CSV_ENCODING = "utf-8"
    
    # Authentication
    KEYCHAIN_SERVICE = 'azure-role-assignment-exporter'
    KEYCHAIN_ACCOUNT = 'azure-credentials'
    KEYCHAIN_UPDATE_FLAG = '-U'
    
    # Environment variables
    TOKEN_ENV_VARS = [
        'AZURE_ACCESS_TOKEN', 'AZURE_TOKEN', 'ARM_ACCESS_TOKEN'
    ]
    
    # HTTP status codes
    HTTP_OK = 200
    HTTP_UNAUTHORIZED = 401
    HTTP_FORBIDDEN = 403
    HTTP_NOT_FOUND = 404
    HTTP_RATE_LIMITED = 429
    HTTP_SERVER_ERROR = 500
    
    # Output formatting
    SEPARATOR_LENGTH = 80
    SUBSECTION_SEPARATOR_LENGTH = 60
    
    # Exit codes
    EXIT_CODE_SUCCESS = 0
    EXIT_CODE_ERROR = 1
    EXIT_CODE_INTERRUPT = 130
    
    # Scan depth levels
    DEPTH_MANAGEMENT_GROUPS = 'management-groups'
    DEPTH_SUBSCRIPTIONS = 'subscriptions'
    DEPTH_RESOURCE_GROUPS = 'resource-groups'
    DEPTH_RESOURCES = 'resources'
    DEFAULT_DEPTH = DEPTH_MANAGEMENT_GROUPS
    
    # Resource scanning limits
    DEFAULT_MAX_RESOURCES = 10000
    DEFAULT_API_DELAY = 0.1  # seconds between API calls
    RATE_LIMIT_RETRY_DELAY = 60  # seconds to wait on 429
    MAX_RETRY_ATTEMPTS = 3
    
    # Resource API version
    RESOURCE_API_VERSION = "2021-04-01"
    
    # Logging
    DEFAULT_LOG_FORMAT = '%(asctime)s - %(levelname)s - %(message)s'
    DEFAULT_DATE_FORMAT = '%H:%M:%S'


def safe_print(*args, **kwargs):
    """Print function that handles BrokenPipeError gracefully."""
    try:
        print(*args, **kwargs)
    except BrokenPipeError:
        try:
            sys.stdout.close()
        except OSError:
            pass
        sys.exit(0)


# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format=ARAConfig.DEFAULT_LOG_FORMAT,
    datefmt=ARAConfig.DEFAULT_DATE_FORMAT
)
logger = logging.getLogger(__name__)


# Custom Exceptions
class ARAError(Exception):
    """Base exception for ARA errors."""
    pass


class AuthenticationError(ARAError):
    """Raised when authentication fails."""
    pass


class APIError(ARAError):
    """Raised when API operations fail."""
    pass


class ExportError(ARAError):
    """Raised when export operations fail."""
    pass


class ValidationError(ARAError):
    """Raised when validation fails."""
    pass


# Progress Tracking
class ProgressTracker:
    """Progress tracking with optional tqdm support."""
    
    def __init__(self, total: int, desc: str = "Progress", disable: bool = False):
        """Initialize progress tracker.
        
        Args:
            total: Total number of items to process
            desc: Description of the progress
            disable: Disable progress display
        """
        self.total = total
        self.desc = desc
        self.current = 0
        self.start_time = time.time()
        self.disable = disable
        self.tqdm_available = False
        self.pbar = None
        
        # Try to import tqdm
        if not disable:
            try:
                from tqdm import tqdm
                self.tqdm_available = True
                self.pbar = tqdm(total=total, desc=desc, unit="scope")
            except ImportError:
                # Fall back to simple text progress
                self.tqdm_available = False
                logger.debug("tqdm not available, using simple progress display")
    
    def update(self, n: int = 1):
        """Update progress by n items."""
        if self.disable:
            return
            
        self.current += n
        
        if self.tqdm_available and self.pbar:
            self.pbar.update(n)
        else:
            # Simple text-based progress
            self._print_simple_progress()
    
    def _print_simple_progress(self):
        """Print simple text-based progress."""
        if self.total == 0:
            return
            
        percentage = (self.current / self.total) * 100
        elapsed = time.time() - self.start_time
        
        if self.current > 0:
            rate = self.current / elapsed
            eta_seconds = (self.total - self.current) / rate if rate > 0 else 0
            eta_str = self._format_time(eta_seconds)
            rate_str = f"{rate:.1f}" if rate < 10 else f"{rate:.0f}"
        else:
            eta_str = "?"
            rate_str = "0"
        
        # Create progress bar visual
        bar_width = 20
        filled = int(bar_width * self.current / self.total)
        bar = "‚ñà" * filled + "‚ñë" * (bar_width - filled)
        
        # Clear line and print progress
        sys.stderr.write(f"\r{self.desc}: [{bar}] {self.current}/{self.total} ({percentage:.0f}%) | ETA: {eta_str} | {rate_str} scopes/s")
        sys.stderr.flush()
        
        # Print newline when complete
        if self.current >= self.total:
            sys.stderr.write("\n")
            sys.stderr.flush()
    
    def _format_time(self, seconds: float) -> str:
        """Format seconds into human-readable time."""
        if seconds < 60:
            return f"{int(seconds)}s"
        elif seconds < 3600:
            minutes = int(seconds / 60)
            secs = int(seconds % 60)
            return f"{minutes}m {secs}s"
        else:
            hours = int(seconds / 3600)
            minutes = int((seconds % 3600) / 60)
            return f"{hours}h {minutes}m"
    
    def close(self):
        """Close the progress tracker."""
        if self.tqdm_available and self.pbar:
            self.pbar.close()
        elif not self.disable and self.current < self.total:
            # Ensure we end the line if not completed
            sys.stderr.write("\n")
            sys.stderr.flush()
    
    def __enter__(self):
        """Context manager entry."""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit."""
        self.close()
        return False


class AssignmentFilter:
    """Filter role assignments based on various criteria."""
    
    def __init__(self, args):
        """Initialize filters from command-line arguments.
        
        Args:
            args: Parsed command-line arguments
        """
        self.role_filter = self._parse_list_filter(args.role_filter)
        self.principal_type_filter = self._parse_list_filter(args.principal_type_filter)
        self.assignment_type_filter = self._parse_list_filter(getattr(args, 'assignment_type_filter', None))
        self.principal_name_pattern = None
        self.exclude_system = args.exclude_system
        
        # Compile regex pattern for principal name filter
        if args.principal_name_filter:
            try:
                self.principal_name_pattern = re.compile(args.principal_name_filter, re.IGNORECASE)
            except re.error as e:
                raise ValueError(f"Invalid regex pattern in --principal-name-filter: {e}")
    
    @staticmethod
    def _parse_list_filter(filter_value: Optional[str]) -> Optional[List[str]]:
        """Parse comma-separated filter values.
        
        Args:
            filter_value: Comma-separated string or None
            
        Returns:
            List of lowercase values or None
        """
        if not filter_value:
            return None
        return [v.strip().lower() for v in filter_value.split(',') if v.strip()]
    
    def apply(self, assignments: List['RoleAssignment']) -> List['RoleAssignment']:
        """Apply all filters to a list of role assignments.
        
        Args:
            assignments: List of role assignments to filter
            
        Returns:
            Filtered list of role assignments
        """
        if not self.has_filters():
            return assignments
        
        filtered = []
        for assignment in assignments:
            if self._matches(assignment):
                filtered.append(assignment)
        
        return filtered
    
    def has_filters(self) -> bool:
        """Check if any filters are configured.
        
        Returns:
            True if any filters are active
        """
        return bool(
            self.role_filter or
            self.principal_type_filter or
            self.assignment_type_filter or
            self.principal_name_pattern or
            self.exclude_system
        )
    
    def _matches(self, assignment: 'RoleAssignment') -> bool:
        """Check if an assignment matches all filter criteria.
        
        Args:
            assignment: Role assignment to check
            
        Returns:
            True if assignment matches all filters
        """
        # Role filter
        if self.role_filter and assignment.role_name.lower() not in self.role_filter:
            return False
        
        # Principal type filter
        if self.principal_type_filter and assignment.principal_type.lower() not in self.principal_type_filter:
            return False
        
        # Assignment type filter (Active/Eligible)
        if self.assignment_type_filter and assignment.assignment_type.lower() not in self.assignment_type_filter:
            return False
        
        # Principal name pattern filter
        if self.principal_name_pattern and not self.principal_name_pattern.search(assignment.principal_name):
            return False
        
        # Exclude system-assigned managed identities
        if self.exclude_system and assignment.principal_type.lower() == 'serviceprincipal':
            # System-assigned managed identities typically have names matching the resource
            if assignment.principal_name and assignment.principal_name.lower().startswith('system-'):
                return False
        
        return True
    
    def get_summary(self) -> Dict[str, Any]:
        """Get a summary of active filters.
        
        Returns:
            Dictionary describing active filters
        """
        summary = {}
        
        if self.role_filter:
            summary['role_filter'] = ', '.join(self.role_filter)
        
        if self.principal_type_filter:
            summary['principal_type_filter'] = ', '.join(self.principal_type_filter)
        
        if self.assignment_type_filter:
            summary['assignment_type_filter'] = ', '.join(self.assignment_type_filter)
        
        if self.principal_name_pattern:
            summary['principal_name_filter'] = self.principal_name_pattern.pattern
        
        if self.exclude_system:
            summary['exclude_system'] = True
        
        return summary


# Data Models
@dataclass(frozen=True)
class RoleAssignment:
    """Immutable role assignment information."""
    principal_id: str
    principal_name: str
    principal_type: str
    role_name: str
    role_id: str
    scope: str
    scope_name: str
    scope_type: str
    resource_type: Optional[str] = None  # For individual resources
    assignment_type: str = "Active permanent"  # "Active permanent", "Active time-bound", "Eligible permanent", "Eligible time-bound"
    start_date_time: Optional[str] = None  # ISO 8601 format
    end_date_time: Optional[str] = None  # ISO 8601 format
    
    def __post_init__(self):
        """Validate data after initialization."""
        if not self.principal_id:
            raise ValidationError("Principal ID cannot be empty")
        if not self.role_name:
            raise ValidationError("Role name cannot be empty")
        if not self.scope:
            raise ValidationError("Scope cannot be empty")
        valid_types = ("Active permanent", "Active time-bound", "Eligible permanent", "Eligible time-bound")
        if self.assignment_type not in valid_types:
            raise ValidationError(f"Assignment type must be one of {valid_types}, got: {self.assignment_type}")
    
    @property
    def full_scope_path(self) -> str:
        """Get full scope path for display."""
        if self.scope_name:
            return f"{self.scope_name} ({self.scope_type})"
        return self.scope


@dataclass
class Scope:
    """Represents an Azure scope (Management Group, Subscription, Resource Group, or Resource)."""
    scope_path: str
    name: str
    scope_type: str  # 'Management Group', 'Subscription', 'Resource Group', or 'Resource'
    depth: int = 0
    parent_scope: Optional[str] = None
    resource_type: Optional[str] = None  # For individual resources (e.g., 'Microsoft.Compute/virtualMachines')
    
    def __post_init__(self):
        """Validate scope data."""
        if not self.scope_path:
            raise ValidationError("Scope path cannot be empty")
        if not self.name:
            raise ValidationError("Scope name cannot be empty")
        valid_types = ['Management Group', 'Subscription', 'Resource Group', 'Resource']
        if self.scope_type not in valid_types:
            raise ValidationError(f"Invalid scope type: {self.scope_type}. Must be one of {valid_types}")
    
    @staticmethod
    def from_path(scope_path: str, depth: int = 0) -> 'Scope':
        """Create a Scope object from a scope path."""
        path_lower = scope_path.lower()
        
        if '/resourcegroups/' in path_lower:
            parts = scope_path.split('/')
            # Check if it's a resource or just a resource group
            if len(parts) > 5 and '/providers/' in path_lower:
                # It's a resource: /subscriptions/{id}/resourceGroups/{rg}/providers/{provider}/{type}/{name}
                try:
                    rg_index = next(i for i, p in enumerate(parts) if p.lower() == 'resourcegroups')
                    provider_index = next(i for i, p in enumerate(parts) if p.lower() == 'providers' and i > rg_index)
                    resource_name = parts[-1]
                    resource_type = '/'.join(parts[provider_index+1:-1])
                    return Scope(
                        scope_path=scope_path,
                        name=resource_name,
                        scope_type='Resource',
                        depth=depth,
                        resource_type=resource_type
                    )
                except (StopIteration, IndexError):
                    pass
            # It's a resource group: /subscriptions/{id}/resourceGroups/{name}
            try:
                rg_index = next(i for i, p in enumerate(parts) if p.lower() == 'resourcegroups')
                rg_name = parts[rg_index + 1] if rg_index + 1 < len(parts) else 'Unknown'
                return Scope(
                    scope_path=scope_path,
                    name=rg_name,
                    scope_type='Resource Group',
                    depth=depth
                )
            except (StopIteration, IndexError):
                pass
        
        if '/subscriptions/' in path_lower:
            parts = scope_path.split('/')
            sub_id = parts[-1] if parts else 'Unknown'
            return Scope(
                scope_path=scope_path,
                name=sub_id,
                scope_type='Subscription',
                depth=depth
            )
        
        if '/managementgroups/' in path_lower:
            parts = scope_path.split('/')
            mg_id = parts[-1] if parts else 'Unknown'
            return Scope(
                scope_path=scope_path,
                name=mg_id,
                scope_type='Management Group',
                depth=depth
            )
        
        # Default fallback
        return Scope(
            scope_path=scope_path,
            name='Unknown',
            scope_type='Subscription',
            depth=depth
        )


@dataclass
class ScanResult:
    """Results container for role assignment scan."""
    organization: str
    scope: str
    scan_timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    total_scopes_scanned: int = 0
    total_assignments_found: int = 0
    assignments: List[RoleAssignment] = field(default_factory=list)
    scanned_scopes: List[Scope] = field(default_factory=list)
    filters_applied: Dict[str, Any] = field(default_factory=dict)
    
    def add_assignment(self, assignment: RoleAssignment):
        """Add a role assignment to results."""
        self.assignments.append(assignment)
        self.total_assignments_found += 1
    
    def add_scanned_scope(self, scope: Scope):
        """Add a scanned scope to results."""
        self.scanned_scopes.append(scope)
        self.total_scopes_scanned += 1


# Authentication System
class AuthenticationProvider(ABC):
    """Abstract base class for authentication providers."""
    
    @abstractmethod
    def get_token(self) -> Optional[str]:
        """Get authentication token."""
        pass
    
    @abstractmethod
    def get_name(self) -> str:
        """Get provider name for logging."""
        pass


class EnvironmentAuthProvider(AuthenticationProvider):
    """Get token from environment variables."""
    
    def get_token(self) -> Optional[str]:
        """Get token from environment variables."""
        for var_name in ARAConfig.TOKEN_ENV_VARS:
            token = os.getenv(var_name)
            if token and token.strip():
                logger.debug(f"Found token in environment variable: {var_name}")
                return token.strip()
        return None
    
    def get_name(self) -> str:
        """Get provider name."""
        return "environment variables"


class AzureCliAuthProvider(AuthenticationProvider):
    """Get token from Azure CLI."""
    
    def get_token(self) -> Optional[str]:
        """Get token from Azure CLI."""
        try:
            import subprocess
            result = subprocess.run(
                ['az', 'account', 'get-access-token', '--resource', ARAConfig.AZURE_MANAGEMENT_URL],
                capture_output=True,
                text=True,
                check=True,
                timeout=ARAConfig.TOKEN_VALIDATION_TIMEOUT
            )
            
            token_data = json.loads(result.stdout)
            token = token_data.get('accessToken')
            if token:
                logger.debug("Retrieved token from Azure CLI")
                return token
        except (subprocess.CalledProcessError, subprocess.TimeoutExpired, FileNotFoundError, json.JSONDecodeError):
            logger.debug("Could not retrieve token from Azure CLI")
        except Exception as e:
            logger.debug(f"Azure CLI access failed: {e}")
        return None
    
    def get_name(self) -> str:
        """Get provider name."""
        return "Azure CLI"


class KeychainAuthProvider(AuthenticationProvider):
    """Get token from macOS Keychain."""
    
    def get_token(self) -> Optional[str]:
        """Get token from macOS Keychain."""
        try:
            import subprocess
            result = subprocess.run(
                ['security', 'find-generic-password', '-s', ARAConfig.KEYCHAIN_SERVICE, 
                 '-a', ARAConfig.KEYCHAIN_ACCOUNT, '-w'],
                capture_output=True,
                text=True,
                check=True,
                timeout=ARAConfig.TOKEN_VALIDATION_TIMEOUT
            )
            
            token = result.stdout.strip()
            if token:
                logger.debug(f"Found token in keychain: {ARAConfig.KEYCHAIN_SERVICE}")
                return token
        except (subprocess.CalledProcessError, subprocess.TimeoutExpired, FileNotFoundError):
            logger.debug(f"Could not retrieve token from keychain")
        except Exception as e:
            logger.debug(f"Keychain access failed: {e}")
        return None
    
    def get_name(self) -> str:
        """Get provider name."""
        return "macOS Keychain"


class InteractiveAuthProvider(AuthenticationProvider):
    """Get token through interactive prompt."""
    
    def get_token(self) -> Optional[str]:
        """Prompt user for token securely."""
        safe_print("\nüîê Azure authentication required.")
        safe_print("   Please provide an Azure access token with permissions to read:")
        safe_print("   ‚Ä¢ Role assignments")
        safe_print("   ‚Ä¢ Management groups")
        safe_print("   ‚Ä¢ Microsoft Graph (for principal name resolution)")
        safe_print()
        safe_print("   You can get a token via:")
        safe_print("   ‚Ä¢ az account get-access-token --resource https://management.azure.com")
        safe_print("   ‚Ä¢ Azure Portal > Cloud Shell > az account get-access-token")
        safe_print()
        
        try:
            import getpass
            token = getpass.getpass("Enter your Azure access token: ").strip()
            if not token:
                logger.warning("No token provided")
                return None
            
            # Offer to save to keychain on macOS
            if sys.platform == 'darwin':
                self._offer_keychain_save(token)
            
            return token
        except KeyboardInterrupt:
            safe_print("\n‚ùå Authentication cancelled by user")
            return None
        except Exception as e:
            logger.error(f"Error during interactive authentication: {e}")
            return None
    
    def _offer_keychain_save(self, token: str):
        """Offer to save token to keychain."""
        try:
            response = input("\nüíæ Save token to macOS Keychain for future use? (y/N): ").strip().lower()
            if response in ['y', 'yes']:
                import subprocess
                subprocess.run([
                    'security', 'add-generic-password',
                    '-s', ARAConfig.KEYCHAIN_SERVICE,
                    '-a', ARAConfig.KEYCHAIN_ACCOUNT,
                    '-w', token,
                    ARAConfig.KEYCHAIN_UPDATE_FLAG
                ], capture_output=True, check=True)
                safe_print("‚úÖ Token saved to keychain")
        except Exception as e:
            logger.debug(f"Could not save to keychain: {e}")
    
    def get_name(self) -> str:
        """Get provider name."""
        return "interactive prompt"


class AzureAuthenticationManager:
    """Manages Azure authentication with multiple providers."""
    
    def __init__(self, allow_interactive: bool = True):
        """Initialize authentication manager."""
        self.providers = [
            EnvironmentAuthProvider(),
            AzureCliAuthProvider(),
            KeychainAuthProvider(),
        ]
        
        if allow_interactive:
            self.providers.append(InteractiveAuthProvider())
    
    def get_token(self, override_token: Optional[str] = None) -> str:
        """Get Azure access token using various methods."""
        if override_token:
            logger.info("Using provided token")
            return override_token
        
        logger.info("üîç Looking for Azure authentication...")
        
        for provider in self.providers:
            try:
                token = provider.get_token()
                if token:
                    if self._validate_token(token):
                        logger.info(f"‚úÖ Authenticated via {provider.get_name()}")
                        return token
                    else:
                        logger.warning(f"‚ùå Invalid token from {provider.get_name()}")
            except Exception as e:
                logger.debug(f"Provider {provider.get_name()} failed: {e}")
        
        raise AuthenticationError("No valid authentication token found")
    
    def _validate_token(self, token: str) -> bool:
        """Validate token by making a test API call."""
        try:
            url = f"{ARAConfig.AZURE_MANAGEMENT_URL}/subscriptions?api-version={ARAConfig.AZURE_API_VERSION}"
            headers = {'Authorization': f'Bearer {token}'}
            
            request = urllib.request.Request(url, headers=headers)
            with urllib.request.urlopen(request, timeout=ARAConfig.TOKEN_VALIDATION_TIMEOUT) as response:
                if response.status == ARAConfig.HTTP_OK:
                    data = json.loads(response.read().decode())
                    sub_count = len(data.get('value', []))
                    logger.debug(f"Token validation successful - found {sub_count} subscriptions")
                    return True
            return False
        except Exception as e:
            logger.debug(f"Token validation failed: {e}")
            return False


# API Clients
class AzureAPIClient:
    """Azure API client with caching, rate limiting, and error handling."""
    
    def __init__(self, token: str, api_delay: float = ARAConfig.DEFAULT_API_DELAY):
        """Initialize API client."""
        if not token:
            raise ValueError("Token cannot be empty")
        
        self.token = token
        self.api_delay = api_delay
        self.headers = {
            'Authorization': f'Bearer {token}',
            'Content-Type': 'application/json',
            'User-Agent': f'AzureRoleAssignmentExporter/{__version__}'
        }
        self._auth_verified = False
        self._last_request_time = 0.0
    
    @functools.lru_cache(maxsize=ARAConfig.CACHE_SIZE_LIMIT)
    def _make_cached_request(self, url: str, params_tuple: tuple = ()) -> Dict:
        """Make a cached request to reduce duplicate API calls."""
        params = dict(params_tuple) if params_tuple else None
        return self._make_request_internal(url, params)
    
    def _make_request(self, url: str, params: Optional[Dict] = None) -> Dict:
        """Public interface for making requests."""
        if params:
            params_tuple = tuple(sorted(params.items()))
            return self._make_cached_request(url, params_tuple)
        else:
            return self._make_cached_request(url)
    
    def _apply_rate_limit(self) -> None:
        """Apply rate limiting between API calls."""
        if self.api_delay > 0:
            current_time = time.time()
            time_since_last = current_time - self._last_request_time
            if time_since_last < self.api_delay:
                time.sleep(self.api_delay - time_since_last)
            self._last_request_time = time.time()
    
    def _make_request_internal(self, url: str, params: Optional[Dict] = None) -> Dict:
        """Make a request to the Azure API with error handling and retry logic."""
        if params:
            url += "?" + urllib.parse.urlencode(params)
        
        request = urllib.request.Request(url, headers=self.headers)
        
        # Retry loop for rate limiting
        for attempt in range(ARAConfig.MAX_RETRY_ATTEMPTS):
            try:
                self._apply_rate_limit()
                
                with urllib.request.urlopen(request, timeout=ARAConfig.API_REQUEST_TIMEOUT) as response:
                    return json.loads(response.read().decode())
                    
            except urllib.error.HTTPError as e:
                if e.code == ARAConfig.HTTP_RATE_LIMITED and attempt < ARAConfig.MAX_RETRY_ATTEMPTS - 1:
                    wait_time = ARAConfig.RATE_LIMIT_RETRY_DELAY * (2 ** attempt)  # Exponential backoff
                    logger.warning(f"Rate limited (429). Waiting {wait_time}s before retry (attempt {attempt + 1}/{ARAConfig.MAX_RETRY_ATTEMPTS})")
                    time.sleep(wait_time)
                    continue
                else:
                    self._handle_http_error(e, url)
            except urllib.error.URLError as e:
                raise APIError(f"Network error: {e}")
            except json.JSONDecodeError as e:
                raise APIError(f"Invalid JSON response: {e}")
        
        raise APIError("Max retry attempts exceeded")
    
    def _handle_http_error(self, error: urllib.error.HTTPError, url: str) -> None:
        """Handle HTTP errors consistently."""
        try:
            error_body = error.read().decode() if error.fp else ""
        except Exception:
            error_body = "Unable to read error response"
        
        error_messages = {
            ARAConfig.HTTP_UNAUTHORIZED: "Authentication failed - check credentials",
            ARAConfig.HTTP_FORBIDDEN: "Access forbidden - insufficient permissions",
            ARAConfig.HTTP_NOT_FOUND: "Resource not found",
            ARAConfig.HTTP_RATE_LIMITED: "Rate limit exceeded - please wait",
            ARAConfig.HTTP_SERVER_ERROR: "Azure API server error",
        }
        
        message = error_messages.get(error.code, f"HTTP {error.code}")
        raise APIError(f"{message}: {error_body}")
    
    def test_authentication(self) -> bool:
        """Test if the token works."""
        if self._auth_verified:
            return True
        
        try:
            url = f"{ARAConfig.AZURE_MANAGEMENT_URL}/subscriptions?api-version={ARAConfig.AZURE_API_VERSION}"
            data = self._make_request(url)
            
            subscription_count = len(data.get('value', []))
            logger.info(f"‚úÖ Authenticated - found {subscription_count} subscriptions")
            self._auth_verified = True
            return True
            
        except APIError as e:
            logger.error(f"‚ùå Authentication test failed: {e}")
            return False


class ManagementGroupClient:
    """Client for Azure Management Group operations."""
    
    def __init__(self, api_client: AzureAPIClient):
        """Initialize management group client."""
        self.api_client = api_client
    
    def get_management_group_id_from_scope(self, scope: str) -> str:
        """Extract management group ID from scope."""
        parts = scope.split('/')
        try:
            mg_index = parts.index('managementGroups')
            return parts[mg_index + 1]
        except (ValueError, IndexError):
            raise ValidationError(
                f"Invalid scope format: {scope}. "
                f"Expected format: /providers/Microsoft.Management/managementGroups/{{mg-id}}"
            )
    
    def get_management_group_hierarchy(self, mg_id: str) -> List[Scope]:
        """Get all child management groups and subscriptions recursively."""
        all_scopes = []
        
        def extract_children_recursive(parent_id: str, parent_name: str, depth: int = 0):
            """Recursively extract management groups and subscriptions."""
            try:
                mg_data = self._get_management_group(parent_id)
                
                # Add current management group
                scope = Scope(
                    scope_path=f"/providers/Microsoft.Management/managementGroups/{parent_id}",
                    name=parent_name or parent_id,
                    scope_type='Management Group',
                    depth=depth
                )
                all_scopes.append(scope)
                
                # Process children
                children = mg_data.get('properties', {}).get('children', [])
                for child in children:
                    child_type = child.get('type', '')
                    child_id = child.get('name', '')
                    child_name = child.get('displayName', child_id)
                    
                    # Handle both formats: with and without leading slash
                    if 'managementGroups' in child_type:
                        extract_children_recursive(child_id, child_name, depth + 1)
                    elif 'subscriptions' in child_type.lower():
                        subscription_scope = Scope(
                            scope_path=f"/subscriptions/{child_id}",
                            name=child_name,
                            scope_type='Subscription',
                            depth=depth + 1
                        )
                        all_scopes.append(subscription_scope)
                        
            except Exception as e:
                logger.warning(f"Could not retrieve children for {parent_id}: {e}")
        
        extract_children_recursive(mg_id, mg_id, 0)
        return all_scopes
    
    def _get_management_group(self, mg_id: str) -> Dict:
        """Get management group details."""
        url = (f"{ARAConfig.AZURE_MANAGEMENT_URL}/providers/Microsoft.Management/"
               f"managementGroups/{mg_id}?api-version={ARAConfig.MGMT_GROUP_API_VERSION}"
               f"&$expand=children&$recurse=false")
        return self.api_client._make_request(url)


class SubscriptionClient:
    """Client for Azure Subscription operations."""
    
    def __init__(self, api_client: AzureAPIClient):
        """Initialize subscription client."""
        self.api_client = api_client
    
    def get_subscription_details(self, subscription_id: str) -> Dict:
        """Get subscription details including display name."""
        url = (f"{ARAConfig.AZURE_MANAGEMENT_URL}/subscriptions/{subscription_id}"
               f"?api-version=2020-01-01")
        try:
            return self.api_client._make_request(url)
        except Exception as e:
            logger.warning(f"Could not retrieve subscription details for {subscription_id}: {e}")
            return {}
    
    def get_subscription_display_name(self, subscription_id: str) -> str:
        """Get the display name for a subscription."""
        details = self.get_subscription_details(subscription_id)
        return details.get('displayName', subscription_id)


class RoleAssignmentClient:
    """Client for Azure Role Assignment operations."""
    
    def __init__(self, api_client: AzureAPIClient):
        """Initialize role assignment client."""
        self.api_client = api_client
        self._role_definition_cache = {}
    
    def get_direct_assignments_for_scope(self, scope: Scope) -> List[Dict]:
        """Get only direct role assignments for a specific scope."""
        assignments_data = []
        
        try:
            url = (f"{ARAConfig.AZURE_MANAGEMENT_URL}{scope.scope_path}/"
                   f"providers/Microsoft.Authorization/roleAssignments"
                   f"?api-version={ARAConfig.AUTH_API_VERSION}")
            
            data = self.api_client._make_request(url)
            
            for assignment in data.get('value', []):
                # Only include assignments directly assigned to this scope
                assignment_scope = assignment.get('properties', {}).get('scope', '').lower()
                if assignment_scope != scope.scope_path.lower():
                    continue
                
                assignments_data.append(assignment)
                
        except Exception as e:
            logger.warning(f"Error retrieving assignments for {scope.name}: {e}")
        
        return assignments_data
    
    def get_role_definition(self, role_def_id: str) -> Optional[str]:
        """Get role definition name with caching."""
        if role_def_id in self._role_definition_cache:
            return self._role_definition_cache[role_def_id]
        
        try:
            url = f"{ARAConfig.AZURE_MANAGEMENT_URL}{role_def_id}?api-version={ARAConfig.AUTH_API_VERSION}"
            data = self.api_client._make_request(url)
            role_name = data.get('properties', {}).get('roleName', 'Unknown')
            self._role_definition_cache[role_def_id] = role_name
            return role_name
        except Exception as e:
            logger.debug(f"Could not fetch role definition: {e}")
            return "Unknown"


class PIMClient:
    """Client for Azure PIM (Privileged Identity Management) operations."""
    
    def __init__(self, api_client: AzureAPIClient):
        """Initialize PIM client."""
        self.api_client = api_client
        self._pim_available = None  # Cache PIM availability status
    
    def get_eligible_assignments_for_scope(self, scope: Scope) -> List[Dict]:
        """Get eligible role assignments (PIM) for a specific scope.
        
        Args:
            scope: Scope to scan
            
        Returns:
            List of eligible assignment data dictionaries
        """
        eligibility_data = []
        
        try:
            # Azure PIM API endpoint for eligible role assignments
            url = (f"{ARAConfig.AZURE_MANAGEMENT_URL}{scope.scope_path}/"
                   f"providers/Microsoft.Authorization/roleEligibilityScheduleInstances"
                   f"?api-version=2020-10-01")
            
            data = self.api_client._make_request(url)
            
            for eligibility in data.get('value', []):
                # Extract the scope from the eligibility
                props = eligibility.get('properties', {})
                eligibility_scope = props.get('scope', '').lower()
                
                # Only include eligible assignments directly assigned to this scope
                if eligibility_scope != scope.scope_path.lower():
                    continue
                
                eligibility_data.append(eligibility)
            
            # Mark PIM as available if we got this far
            if self._pim_available is None:
                self._pim_available = True
                
        except Exception as e:
            # It's common for scopes to not have PIM enabled, so we log at debug level
            logger.debug(f"No eligible assignments or PIM not enabled for {scope.name}: {e}")
            
            # Mark PIM as unavailable on permission errors
            if self._pim_available is None and ('403' in str(e) or '404' in str(e) or 'permission' in str(e).lower()):
                self._pim_available = False
        
        return eligibility_data
    
    def get_time_bound_active_assignments_for_scope(self, scope: Scope) -> List[Dict]:
        """Get time-bound active role assignments (PIM) for a specific scope.
        
        This fetches assignments that were activated through PIM and have an end date.
        
        Args:
            scope: Scope to scan
            
        Returns:
            List of time-bound active assignment data dictionaries
        """
        time_bound_data = []
        
        try:
            # Azure PIM API endpoint for active role assignment schedules
            url = (f"{ARAConfig.AZURE_MANAGEMENT_URL}{scope.scope_path}/"
                   f"providers/Microsoft.Authorization/roleAssignmentScheduleInstances"
                   f"?api-version=2020-10-01")
            
            data = self.api_client._make_request(url)
            
            for assignment in data.get('value', []):
                # Extract the scope from the assignment
                props = assignment.get('properties', {})
                assignment_scope = props.get('scope', '').lower()
                
                # Only include assignments directly assigned to this scope
                if assignment_scope != scope.scope_path.lower():
                    continue
                
                time_bound_data.append(assignment)
                
        except Exception as e:
            # It's common for scopes to not have PIM enabled, so we log at debug level
            logger.debug(f"No time-bound active assignments or PIM not enabled for {scope.name}: {e}")
        
        return time_bound_data
    
    def is_pim_available(self) -> Optional[bool]:
        """Check if PIM is available based on previous API calls.
        
        Returns:
            True if PIM is available, False if unavailable, None if not yet determined
        """
        return self._pim_available


class ResourceGroupClient:
    """Client for Azure Resource Group operations."""
    
    def __init__(self, api_client: AzureAPIClient):
        """Initialize resource group client."""
        self.api_client = api_client
        self._resource_group_cache = {}
    
    @functools.lru_cache(maxsize=ARAConfig.CACHE_SIZE_LIMIT)
    def list_resource_groups(self, subscription_id: str) -> List[Scope]:
        """List all resource groups in a subscription."""
        if subscription_id in self._resource_group_cache:
            return self._resource_group_cache[subscription_id]
        
        resource_groups = []
        try:
            url = (f"{ARAConfig.AZURE_MANAGEMENT_URL}/subscriptions/{subscription_id}/"
                   f"resourcegroups?api-version={ARAConfig.RESOURCE_API_VERSION}")
            
            data = self.api_client._make_request(url)
            
            for rg in data.get('value', []):
                rg_name = rg.get('name', 'Unknown')
                rg_path = rg.get('id', f"/subscriptions/{subscription_id}/resourceGroups/{rg_name}")
                
                scope = Scope(
                    scope_path=rg_path,
                    name=rg_name,
                    scope_type='Resource Group',
                    depth=0
                )
                resource_groups.append(scope)
            
            self._resource_group_cache[subscription_id] = resource_groups
            logger.debug(f"Found {len(resource_groups)} resource groups in subscription {subscription_id}")
            
        except Exception as e:
            logger.warning(f"Error listing resource groups for subscription {subscription_id}: {e}")
        
        return resource_groups


class ResourceClient:
    """Client for Azure Resource operations."""
    
    def __init__(self, api_client: AzureAPIClient):
        """Initialize resource client."""
        self.api_client = api_client
        self._resource_cache = {}
    
    def list_resources(self, subscription_id: str, resource_group_name: str, 
                       resource_type_filter: Optional[List[str]] = None) -> List[Scope]:
        """List all resources in a resource group with optional type filtering."""
        cache_key = f"{subscription_id}/{resource_group_name}"
        if cache_key in self._resource_cache:
            cached_resources = self._resource_cache[cache_key]
            if resource_type_filter:
                return [r for r in cached_resources if r.resource_type in resource_type_filter]
            return cached_resources
        
        resources = []
        try:
            url = (f"{ARAConfig.AZURE_MANAGEMENT_URL}/subscriptions/{subscription_id}/"
                   f"resourceGroups/{resource_group_name}/resources"
                   f"?api-version={ARAConfig.RESOURCE_API_VERSION}")
            
            data = self.api_client._make_request(url)
            
            for resource in data.get('value', []):
                resource_name = resource.get('name', 'Unknown')
                resource_id = resource.get('id', '')
                resource_type = resource.get('type', 'Unknown')
                
                scope = Scope(
                    scope_path=resource_id,
                    name=resource_name,
                    scope_type='Resource',
                    depth=0,
                    resource_type=resource_type
                )
                resources.append(scope)
            
            self._resource_cache[cache_key] = resources
            logger.debug(f"Found {len(resources)} resources in {resource_group_name}")
            
        except Exception as e:
            logger.warning(f"Error listing resources for {resource_group_name}: {e}")
        
        # Apply filter if specified
        if resource_type_filter:
            resources = [r for r in resources if r.resource_type in resource_type_filter]
        
        return resources


class GraphAPIClient:
    """Client for Microsoft Graph API operations."""
    
    def __init__(self):
        """Initialize Graph API client."""
        self.token = None
        self._principal_cache = {}
        self._graph_token_fetched = False
    
    def _get_graph_token(self) -> Optional[str]:
        """Get Graph API token from Azure CLI."""
        if self._graph_token_fetched:
            return self.token
        
        try:
            # Get Graph API token specifically
            cmd = ['az', 'account', 'get-access-token', '--resource', 'https://graph.microsoft.com']
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=ARAConfig.TOKEN_VALIDATION_TIMEOUT
            )
            
            if result.returncode == 0:
                token_data = json.loads(result.stdout)
                self.token = token_data.get('accessToken')
                self._graph_token_fetched = True
                logger.debug("Successfully obtained Graph API token")
                return self.token
            else:
                logger.debug(f"Failed to get Graph token: {result.stderr}")
                self._graph_token_fetched = True
                return None
                
        except Exception as e:
            logger.debug(f"Could not get Graph API token: {e}")
            self._graph_token_fetched = True
            return None
    
    def get_principal_display_name(self, principal_id: str, principal_type: str) -> str:
        """Get the display name for a principal."""
        # Check cache first
        if principal_id in self._principal_cache:
            return self._principal_cache[principal_id]
        
        # Try to fetch from Graph API
        try:
            display_name = self._fetch_principal_name(principal_id, principal_type)
            self._principal_cache[principal_id] = display_name
            return display_name
        except Exception as e:
            logger.debug(f"Could not resolve principal {principal_id}: {e}")
            # Fallback to "Unknown" (matches Azure Portal behavior)
            self._principal_cache[principal_id] = "Unknown"
            return "Unknown"
    
    def _fetch_principal_name(self, principal_id: str, principal_type: str) -> str:
        """Fetch principal name from Graph API."""
        # Get Graph token if not already obtained
        token = self._get_graph_token()
        if not token:
            # No token available, return ID
            return principal_id
        
        # Endpoint mapping based on principal type
        endpoint_map = {
            'User': 'users',
            'Group': 'groups',
            'ServicePrincipal': 'servicePrincipals'
        }
        
        endpoint = endpoint_map.get(principal_type, 'directoryObjects')
        url = f"{ARAConfig.GRAPH_API_URL}/{endpoint}/{principal_id}"
        
        headers = {
            'Authorization': f'Bearer {token}',
            'Content-Type': 'application/json',
        }
        
        try:
            request = urllib.request.Request(url, headers=headers)
            with urllib.request.urlopen(request, timeout=ARAConfig.API_REQUEST_TIMEOUT) as response:
                data = json.loads(response.read().decode())
                display_name = data.get('displayName', data.get('userPrincipalName', 'Unknown'))
                logger.debug(f"Resolved {principal_id} -> {display_name}")
                return display_name
                
        except urllib.error.HTTPError as e:
            error_body = e.read().decode() if hasattr(e, 'read') else ''
            logger.debug(f"Graph API HTTP error for {principal_id}: {e.code} - {error_body}")
            return "Unknown"
        except Exception as e:
            logger.debug(f"Graph API error for {principal_id}: {e}")
            return "Unknown"


# Output Handlers
class OutputHandler(ABC):
    """Abstract base class for output handlers."""
    
    @abstractmethod
    def generate(self, results: ScanResult, **kwargs) -> None:
        """Generate output in specific format."""
        pass


class SummaryOutputHandler(OutputHandler):
    """Generate console summary output."""
    
    def generate(self, results: ScanResult, **kwargs) -> None:
        """Generate detailed summary output."""
        safe_print("\n" + "="*ARAConfig.SEPARATOR_LENGTH)
        safe_print(f"üìã SUMMARY: Found {results.total_assignments_found} role assignments "
                  f"across {results.total_scopes_scanned} scopes")
        safe_print("="*ARAConfig.SEPARATOR_LENGTH)
        
        if not results.assignments:
            safe_print("‚ùå No role assignments found.")
            return
        
        # Group by role
        by_role = {}
        for assignment in results.assignments:
            if assignment.role_name not in by_role:
                by_role[assignment.role_name] = []
            by_role[assignment.role_name].append(assignment)
        
        for role_name in sorted(by_role.keys()):
            assignments = by_role[role_name]
            safe_print(f"\nüë§ Role: {role_name} ({len(assignments)} assignments)")
            safe_print("-" * ARAConfig.SUBSECTION_SEPARATOR_LENGTH)
            
            for assignment in assignments[:5]:  # Show top 5
                safe_print(f"   ‚Ä¢ {assignment.principal_name} ({assignment.principal_type})")
                scope_display = f"     Scope: {assignment.scope_name} ({assignment.scope_type})"
                if assignment.resource_type:
                    scope_display += f" - {assignment.resource_type}"
                safe_print(scope_display)
            
            if len(assignments) > 5:
                safe_print(f"   ... and {len(assignments) - 5} more")
        
        safe_print()


class JSONOutputHandler(OutputHandler):
    """Generate JSON output."""
    
    def __init__(self, results_dir: str = ARAConfig.RESULTS_DIR):
        """Initialize JSON handler."""
        self.results_dir = results_dir
        os.makedirs(self.results_dir, exist_ok=True)
    
    def generate(self, results: ScanResult, filename: Optional[str] = None, **kwargs) -> str:
        """Write results to JSON file."""
        output_data = self._build_json_structure(results)
        
        if not filename:
            # Extract management group ID from scope
            parts = results.scope.split('/')
            mg_id = parts[-1] if parts else "unknown"
            filename = f"role_assignments_{mg_id}.json"
        
        filepath = os.path.join(self.results_dir, filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, indent=ARAConfig.JSON_INDENT, ensure_ascii=False)
            logger.info(f"üíæ JSON results saved to: {filepath}")
            return filepath
        except (OSError, TypeError, ValueError) as e:
            raise ExportError(f"Failed to write JSON file: {e}")
    
    def _build_json_structure(self, results: ScanResult) -> Dict:
        """Build JSON output structure."""
        metadata = {
            "tool": "Azure Role Assignment Exporter (ARA)",
            "version": __version__,
            "scan_timestamp": results.scan_timestamp,
            "scope": results.scope,
            "total_scopes_scanned": results.total_scopes_scanned,
            "total_assignments_found": results.total_assignments_found
        }
        
        # Add filter information if filters were applied
        if results.filters_applied:
            metadata["filters_applied"] = results.filters_applied
        
        return {
            "metadata": metadata,
            "scopes_scanned": [
                {
                    "scope_path": scope.scope_path,
                    "name": scope.name,
                    "type": scope.scope_type,
                    "depth": scope.depth
                }
                for scope in results.scanned_scopes
            ],
            "role_assignments": [
                {
                    "principal_id": assignment.principal_id,
                    "principal_name": assignment.principal_name,
                    "principal_type": assignment.principal_type,
                    "role_name": assignment.role_name,
                    "role_id": assignment.role_id,
                    "scope": assignment.scope,
                    "scope_name": assignment.scope_name,
                    "scope_type": assignment.scope_type,
                    "resource_type": assignment.resource_type,
                    "assignment_type": assignment.assignment_type,
                    "start_date_time": assignment.start_date_time,
                    "end_date_time": assignment.end_date_time
                }
                for assignment in results.assignments
            ]
        }


class CSVOutputHandler(OutputHandler):
    """Generate CSV output."""
    
    def __init__(self, results_dir: str = ARAConfig.RESULTS_DIR):
        """Initialize CSV handler."""
        self.results_dir = results_dir
        os.makedirs(self.results_dir, exist_ok=True)
    
    def generate(self, results: ScanResult, filename: Optional[str] = None, **kwargs) -> str:
        """Write results to CSV file."""
        if not filename:
            # Extract management group ID from scope
            parts = results.scope.split('/')
            mg_id = parts[-1] if parts else "unknown"
            filename = f"role_assignments_{mg_id}.csv"
        
        filepath = os.path.join(self.results_dir, filename)
        
        # Check if any assignments have resource_type (for conditional column)
        has_resource_types = any(a.resource_type for a in results.assignments)
        
        try:
            with open(filepath, 'w', newline='', encoding=ARAConfig.CSV_ENCODING) as f:
                fieldnames = ['Name', 'Principal ID', 'Type', 'Role', 'Scope', 'Scope Type', 'Assignment Type']
                if has_resource_types:
                    fieldnames.append('Resource Type')
                fieldnames.extend(['Start Date', 'End Date'])
                
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                
                for assignment in sorted(results.assignments, key=lambda x: x.role_name):
                    row = {
                        'Name': assignment.principal_name,
                        'Principal ID': assignment.principal_id,
                        'Type': assignment.principal_type,
                        'Role': assignment.role_name,
                        'Scope': assignment.scope_name,
                        'Scope Type': assignment.scope_type,
                        'Assignment Type': assignment.assignment_type
                    }
                    if has_resource_types:
                        row['Resource Type'] = assignment.resource_type or ''
                    row['Start Date'] = assignment.start_date_time or ''
                    row['End Date'] = assignment.end_date_time or ''
                    writer.writerow(row)
            
            logger.info(f"üíæ CSV results saved to: {filepath}")
            return filepath
        except (OSError, csv.Error) as e:
            raise ExportError(f"Failed to write CSV file: {e}")


class ExcelOutputHandler(OutputHandler):
    """Generate Excel (.xlsx) output with multiple sheets."""
    
    def __init__(self, results_dir: str = ARAConfig.RESULTS_DIR):
        """Initialize Excel handler."""
        self.results_dir = results_dir
        os.makedirs(self.results_dir, exist_ok=True)
        
        # Check if openpyxl is available
        try:
            global openpyxl
            import openpyxl
            from openpyxl.styles import Font, PatternFill, Alignment
            from openpyxl.utils import get_column_letter
            self.openpyxl_available = True
        except ImportError:
            self.openpyxl_available = False
            logger.warning("‚ö†Ô∏è  openpyxl not installed. Excel output will not be available.")
            logger.warning("   Install with: pip install openpyxl")
    
    def generate(self, results: ScanResult, filename: Optional[str] = None, **kwargs) -> str:
        """Write results to Excel file with multiple sheets."""
        if not self.openpyxl_available:
            raise ExportError(
                "Excel output requires openpyxl library.\n"
                "Install it with: pip install openpyxl"
            )
        
        from openpyxl import Workbook
        from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
        from openpyxl.utils import get_column_letter
        
        if not filename:
            # Extract management group ID from scope
            parts = results.scope.split('/')
            mg_id = parts[-1] if parts else "unknown"
            filename = f"role_assignments_{mg_id}.xlsx"
        
        filepath = os.path.join(self.results_dir, filename)
        
        try:
            wb = Workbook()
            
            # Remove default sheet
            if 'Sheet' in wb.sheetnames:
                wb.remove(wb['Sheet'])
            
            # Sheet 1: Role Assignments
            self._create_assignments_sheet(wb, results)
            
            # Sheet 2: Summary Statistics
            self._create_summary_sheet(wb, results)
            
            # Sheet 3: Metadata
            self._create_metadata_sheet(wb, results)
            
            # Save workbook
            wb.save(filepath)
            logger.info(f"üíæ Excel results saved to: {filepath}")
            return filepath
            
        except Exception as e:
            raise ExportError(f"Failed to write Excel file: {e}")
    
    def _create_assignments_sheet(self, wb, results: ScanResult):
        """Create the main assignments sheet."""
        from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
        from openpyxl.utils import get_column_letter
        
        ws = wb.create_sheet("Role Assignments", 0)
        
        # Check if any assignments have resource_type
        has_resource_types = any(a.resource_type for a in results.assignments)
        
        # Headers
        headers = ['Principal Name', 'Principal ID', 'Principal Type', 'Role', 
                   'Scope Name', 'Scope Type', 'Assignment Type']
        if has_resource_types:
            headers.append('Resource Type')
        headers.extend(['Start Date', 'End Date'])
        
        # Style definitions
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        header_alignment = Alignment(horizontal="center", vertical="center")
        border = Border(
            left=Side(style='thin'),
            right=Side(style='thin'),
            top=Side(style='thin'),
            bottom=Side(style='thin')
        )
        
        # Write headers
        for col_num, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col_num)
            cell.value = header
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = header_alignment
            cell.border = border
        
        # Write data
        for row_num, assignment in enumerate(sorted(results.assignments, key=lambda x: x.role_name), 2):
            data = [
                assignment.principal_name,
                assignment.principal_id,
                assignment.principal_type,
                assignment.role_name,
                assignment.scope_name,
                assignment.scope_type,
                assignment.assignment_type
            ]
            if has_resource_types:
                data.append(assignment.resource_type or '')
            data.extend([
                assignment.start_date_time or '',
                assignment.end_date_time or ''
            ])
            
            for col_num, value in enumerate(data, 1):
                cell = ws.cell(row=row_num, column=col_num)
                cell.value = value
                cell.border = border
                cell.alignment = Alignment(vertical="center")
        
        # Auto-size columns
        for col_num in range(1, len(headers) + 1):
            col_letter = get_column_letter(col_num)
            max_length = 0
            for cell in ws[col_letter]:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            adjusted_width = min(max_length + 2, 50)
            ws.column_dimensions[col_letter].width = adjusted_width
        
        # Freeze header row
        ws.freeze_panes = "A2"
        
        # Add filters
        ws.auto_filter.ref = ws.dimensions
    
    def _create_summary_sheet(self, wb, results: ScanResult):
        """Create summary statistics sheet."""
        from openpyxl.styles import Font, PatternFill, Alignment
        
        ws = wb.create_sheet("Summary", 1)
        
        # Title
        ws['A1'] = "Role Assignment Summary"
        ws['A1'].font = Font(size=16, bold=True)
        ws.merge_cells('A1:B1')
        
        # Count assignments by role
        role_counts = {}
        for assignment in results.assignments:
            role_counts[assignment.role_name] = role_counts.get(assignment.role_name, 0) + 1
        
        # Count assignments by principal type
        type_counts = {}
        for assignment in results.assignments:
            type_counts[assignment.principal_type] = type_counts.get(assignment.principal_type, 0) + 1
        
        # Count assignments by scope type
        scope_counts = {}
        for assignment in results.assignments:
            scope_counts[assignment.scope_type] = scope_counts.get(assignment.scope_type, 0) + 1
        
        # Count assignments by assignment type (PIM)
        assignment_type_counts = {}
        for assignment in results.assignments:
            assignment_type_counts[assignment.assignment_type] = assignment_type_counts.get(assignment.assignment_type, 0) + 1
        
        row = 3
        
        # Overall stats
        ws[f'A{row}'] = "Total Assignments:"
        ws[f'B{row}'] = results.total_assignments_found
        ws[f'A{row}'].font = Font(bold=True)
        row += 1
        
        ws[f'A{row}'] = "Total Scopes Scanned:"
        ws[f'B{row}'] = results.total_scopes_scanned
        ws[f'A{row}'].font = Font(bold=True)
        row += 2
        
        # By Role
        ws[f'A{row}'] = "Assignments by Role"
        ws[f'A{row}'].font = Font(bold=True, size=12)
        ws.merge_cells(f'A{row}:B{row}')
        row += 1
        
        for role, count in sorted(role_counts.items(), key=lambda x: x[1], reverse=True):
            ws[f'A{row}'] = role
            ws[f'B{row}'] = count
            row += 1
        row += 1
        
        # By Principal Type
        ws[f'A{row}'] = "Assignments by Principal Type"
        ws[f'A{row}'].font = Font(bold=True, size=12)
        ws.merge_cells(f'A{row}:B{row}')
        row += 1
        
        for ptype, count in sorted(type_counts.items(), key=lambda x: x[1], reverse=True):
            ws[f'A{row}'] = ptype
            ws[f'B{row}'] = count
            row += 1
        row += 1
        
        # By Scope Type
        ws[f'A{row}'] = "Assignments by Scope Type"
        ws[f'A{row}'].font = Font(bold=True, size=12)
        ws.merge_cells(f'A{row}:B{row}')
        row += 1
        
        for stype, count in sorted(scope_counts.items(), key=lambda x: x[1], reverse=True):
            ws[f'A{row}'] = stype
            ws[f'B{row}'] = count
            row += 1
        row += 1
        
        # By Assignment Type (PIM)
        ws[f'A{row}'] = "Assignments by Type (PIM)"
        ws[f'A{row}'].font = Font(bold=True, size=12)
        ws.merge_cells(f'A{row}:B{row}')
        row += 1
        
        # Sort assignment types in a specific order for better readability
        assignment_type_order = ["Active permanent", "Active time-bound", "Eligible permanent", "Eligible time-bound"]
        for atype in assignment_type_order:
            if atype in assignment_type_counts:
                ws[f'A{row}'] = atype
                ws[f'B{row}'] = assignment_type_counts[atype]
                row += 1
        
        # Column widths
        ws.column_dimensions['A'].width = 35
        ws.column_dimensions['B'].width = 15
    
    def _create_metadata_sheet(self, wb, results: ScanResult):
        """Create metadata sheet."""
        from openpyxl.styles import Font
        
        ws = wb.create_sheet("Metadata", 2)
        
        # Title
        ws['A1'] = "Scan Metadata"
        ws['A1'].font = Font(size=16, bold=True)
        ws.merge_cells('A1:B1')
        
        # Metadata
        metadata = [
            ("Tool", "Azure Role Assignment Exporter (ARA)"),
            ("Version", __version__),
            ("Scan Timestamp", results.scan_timestamp),
            ("Scope", results.scope),
            ("Total Scopes Scanned", results.total_scopes_scanned),
            ("Total Assignments Found", results.total_assignments_found),
        ]
        
        # Add filter information if filters were applied
        if results.filters_applied:
            metadata.append(("", ""))  # Empty row separator
            metadata.append(("Filters Applied", ""))
            for key, value in results.filters_applied.items():
                metadata.append((f"  {key}", str(value)))
        
        row = 3
        for key, value in metadata:
            ws[f'A{row}'] = key
            ws[f'B{row}'] = value
            if value and not key.startswith("  "):  # Bold unless it's a filter detail
                ws[f'A{row}'].font = Font(bold=True)
            row += 1
        
        # Column widths
        ws.column_dimensions['A'].width = 30
        ws.column_dimensions['B'].width = 50


# Main Application
class ARAApplication:
    """Main ARA application class."""
    
    def __init__(self, results_dir: str = ARAConfig.RESULTS_DIR):
        """Initialize ARA application."""
        self.results_dir = results_dir
        self.output_handlers = {
            'summary': SummaryOutputHandler(),
            'json': JSONOutputHandler(results_dir),
            'csv': CSVOutputHandler(results_dir),
            'xlsx': ExcelOutputHandler(results_dir),
        }
    
    def run(self, args: argparse.Namespace) -> int:
        """Run the ARA application."""
        try:
            # Get authentication token
            auth_manager = AzureAuthenticationManager(allow_interactive=True)
            token = auth_manager.get_token(args.token)
            
            # Initialize API clients with rate limiting
            api_client = AzureAPIClient(token, api_delay=args.api_delay)
            if not api_client.test_authentication():
                return ARAConfig.EXIT_CODE_ERROR
            
            # Initialize basic clients
            mg_client = ManagementGroupClient(api_client)
            ra_client = RoleAssignmentClient(api_client)
            pim_client = PIMClient(api_client)  # PIM eligible and time-bound assignments
            graph_client = GraphAPIClient()  # Gets its own Graph token
            
            # Normalize scope - support multiple formats for both MG and subscriptions
            scope = args.scope
            scope_type = None  # Will be 'ManagementGroup' or 'Subscription'
            
            if not scope.startswith('/'):
                # Detect if it's a subscription GUID format (8-4-4-4-12 hex pattern)
                import re
                guid_pattern = r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$'
                
                if re.match(guid_pattern, scope, re.IGNORECASE):
                    # It's a subscription GUID
                    scope = f"/subscriptions/{scope}"
                    scope_type = 'Subscription'
                elif scope.startswith('subscriptions/'):
                    # Short format: subscriptions/{guid}
                    scope = f"/{scope}"
                    scope_type = 'Subscription'
                elif '/' not in scope:
                    # Just an ID - assume it's a management group
                    scope = f"/providers/Microsoft.Management/managementGroups/{scope}"
                    scope_type = 'ManagementGroup'
                elif scope.startswith('managementGroups/'):
                    # Short format: managementGroups/my-mg
                    scope = f"/providers/Microsoft.Management/{scope}"
                    scope_type = 'ManagementGroup'
                else:
                    raise ValidationError(
                        f"Invalid scope format: {args.scope}\n"
                        f"Supported formats:\n"
                        f"  Management Group:\n"
                        f"    - ID: my-mg\n"
                        f"    - Short: managementGroups/my-mg\n"
                        f"    - Full: /providers/Microsoft.Management/managementGroups/my-mg\n"
                        f"  Subscription:\n"
                        f"    - GUID: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n"
                        f"    - Short: subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n"
                        f"    - Full: /subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
                    )
            else:
                # Full path provided - detect type
                if '/subscriptions/' in scope:
                    scope_type = 'Subscription'
                elif '/managementGroups/' in scope:
                    scope_type = 'ManagementGroup'
                else:
                    raise ValidationError(
                        f"Scope must be a management group or subscription. Got: {args.scope}"
                    )
            
            # Validate depth based on scope type
            if scope_type == 'Subscription':
                # For subscription scope, auto-adjust default depth
                if args.depth == ARAConfig.DEFAULT_DEPTH:  # management-groups is default
                    logger.info(f"‚ÑπÔ∏è  Auto-adjusting depth from '{args.depth}' to 'resource-groups' for subscription scope")
                    args.depth = ARAConfig.DEPTH_RESOURCE_GROUPS
                elif args.depth == ARAConfig.DEPTH_MANAGEMENT_GROUPS:
                    raise ValidationError(
                        f"Invalid depth '{args.depth}' for subscription scope.\n"
                        f"Subscription scopes cannot scan management groups.\n"
                        f"Valid depths: resource-groups, resources"
                    )
                elif args.depth == ARAConfig.DEPTH_SUBSCRIPTIONS:
                    raise ValidationError(
                        f"Invalid depth '{args.depth}' for subscription scope.\n"
                        f"The scope is already a subscription. Use 'resource-groups' or 'resources' to scan deeper,\n"
                        f"or omit --depth to scan only the subscription itself."
                    )
            
            # Initialize depth-dependent clients (after depth may have been auto-adjusted)
            sub_client = SubscriptionClient(api_client)
            rg_client = ResourceGroupClient(api_client) if args.depth in [ARAConfig.DEPTH_RESOURCE_GROUPS, ARAConfig.DEPTH_RESOURCES] else None
            res_client = ResourceClient(api_client) if args.depth == ARAConfig.DEPTH_RESOURCES else None
            
            # Initialize assignment filter
            assignment_filter = AssignmentFilter(args)
            if assignment_filter.has_filters():
                logger.info("üìå Active Filters:")
                for key, value in assignment_filter.get_summary().items():
                    logger.info(f"   {key}: {value}")
                logger.info("")
            
            # Get scopes to scan based on scope type
            if scope_type == 'ManagementGroup':
                mg_id = mg_client.get_management_group_id_from_scope(scope)
                logger.info(f"üìÇ Management Group ID: {mg_id}")
                logger.info(f"üéØ Scan Depth: {args.depth}")
                
                # Get all scopes in hierarchy
                logger.info("\nüîç Discovering child management groups and subscriptions...")
                all_scopes = mg_client.get_management_group_hierarchy(mg_id)
                logger.info(f"‚úÖ Found {len(all_scopes)} scope(s) to process\n")
                
                # Scan each scope for role assignments
                results = ScanResult(
                    organization=mg_id,
                    scope=scope,
                    filters_applied=assignment_filter.get_summary()
                )
            else:  # Subscription scope
                subscription_id = scope.split('/')[-1]
                
                # Get subscription display name
                subscription_name = sub_client.get_subscription_display_name(subscription_id)
                
                logger.info(f"üìÇ Subscription: {subscription_name}")
                logger.info(f"   ID: {subscription_id}")
                logger.info(f"üéØ Scan Depth: {args.depth}")
                
                # Create a single-scope list with just this subscription (with display name)
                logger.info("\nüîç Scanning subscription...")
                subscription_scope = Scope(
                    scope_path=scope,
                    name=subscription_name,
                    scope_type='Subscription',
                    depth=0
                )
                all_scopes = [subscription_scope]
                logger.info(f"‚úÖ Ready to scan\n")
                
                # Scan the subscription
                results = ScanResult(
                    organization=subscription_name,
                    scope=scope,
                    filters_applied=assignment_filter.get_summary()
                )
            
            resource_count = 0
            
            # Initialize progress tracker
            # Disable progress if debug mode is on or if explicitly disabled
            show_progress = not (args.debug or args.no_progress)
            
            with ProgressTracker(total=len(all_scopes), desc="Scanning scopes", disable=not show_progress) as progress:
                for scope in all_scopes:
                    # If depth is management-groups only, skip subscriptions entirely
                    if args.depth == ARAConfig.DEPTH_MANAGEMENT_GROUPS and scope.scope_type == 'Subscription':
                        progress.update(1)
                        continue
                    
                    results.add_scanned_scope(scope)
                    indent = "  " * scope.depth
                    logger.info(f"{indent}üîç Scanning: {scope.name} ({scope.scope_type})")
                    
                    # Get direct assignments for current scope
                    self._scan_scope_assignments(scope, results, ra_client, pim_client, graph_client, indent, assignment_filter, args)
                    
                    # If this is a subscription and we want deeper scanning
                    if scope.scope_type == 'Subscription' and args.depth in [ARAConfig.DEPTH_RESOURCE_GROUPS, ARAConfig.DEPTH_RESOURCES]:
                        subscription_id = scope.scope_path.split('/')[-1]
                        
                        # Get resource groups
                        logger.info(f"{indent}  üì¶ Listing resource groups...")
                        resource_groups = rg_client.list_resource_groups(subscription_id)
                        logger.info(f"{indent}  ‚úÖ Found {len(resource_groups)} resource group(s)")
                        
                        for rg in resource_groups:
                            if resource_count >= args.max_resources:
                                logger.warning(f"{indent}    ‚ö†Ô∏è  Reached max resource limit ({args.max_resources}). Stopping resource scan.")
                                break
                            
                            results.add_scanned_scope(rg)
                            rg_indent = indent + "    "
                            logger.info(f"{rg_indent}üîç Scanning: {rg.name} (Resource Group)")
                            
                            # Scan resource group assignments
                            self._scan_scope_assignments(rg, results, ra_client, pim_client, graph_client, rg_indent, assignment_filter, args)
                            
                            # If we want individual resources
                            if args.depth == ARAConfig.DEPTH_RESOURCES:
                                rg_name = rg.name
                                logger.info(f"{rg_indent}  üì¶ Listing resources...")
                                resources = res_client.list_resources(subscription_id, rg_name, args.resource_types)
                                logger.info(f"{rg_indent}  ‚úÖ Found {len(resources)} resource(s)")
                                
                                for resource in resources:
                                    if resource_count >= args.max_resources:
                                        logger.warning(f"{rg_indent}    ‚ö†Ô∏è  Reached max resource limit ({args.max_resources}). Stopping.")
                                        break
                                    
                                    results.add_scanned_scope(resource)
                                    res_indent = rg_indent + "      "
                                    logger.info(f"{res_indent}üîç {resource.name} ({resource.resource_type})")
                                    
                                    # Scan individual resource assignments
                                    self._scan_scope_assignments(resource, results, ra_client, pim_client, graph_client, res_indent, assignment_filter, args)
                                    resource_count += 1
                    
                    # Update progress after processing each scope
                    progress.update(1)
            
            logger.info(f"\n‚úÖ Scan complete: {results.total_assignments_found} assignments "
                       f"across {results.total_scopes_scanned} scopes")
            
            # Generate outputs
            if args.format == 'json':
                self.output_handlers['json'].generate(results)
            elif args.format == 'csv':
                self.output_handlers['csv'].generate(results)
            elif args.format == 'xlsx':
                self.output_handlers['xlsx'].generate(results)
            
            # Always show summary
            self.output_handlers['summary'].generate(results)
            
            logger.info("üéâ ARA completed successfully!")
            return ARAConfig.EXIT_CODE_SUCCESS
            
        except KeyboardInterrupt:
            logger.info("\n‚ùå Operation cancelled by user")
            return ARAConfig.EXIT_CODE_INTERRUPT
        except (AuthenticationError, ValidationError, APIError, ExportError) as e:
            logger.error(f"‚ùå Error: {e}")
            return ARAConfig.EXIT_CODE_ERROR
        except Exception as e:
            logger.error(f"‚ùå Unexpected error: {e}")
            if args.debug:
                import traceback
                traceback.print_exc()
            return ARAConfig.EXIT_CODE_ERROR
    
    def _scan_scope_assignments(self, scope: Scope, results: ScanResult, 
                                ra_client: RoleAssignmentClient,
                                pim_client: PIMClient,
                                graph_client: GraphAPIClient, 
                                indent: str,
                                assignment_filter: Optional['AssignmentFilter'] = None,
                                args=None) -> None:
        """Scan role assignments (both active and eligible via PIM) for a specific scope.
        
        Args:
            scope: Scope to scan
            results: Results object to add assignments to
            ra_client: Role assignment client (standard RBAC)
            pim_client: PIM client (eligible and time-bound assignments)
            graph_client: Graph API client
            indent: Logging indentation
            assignment_filter: Optional filter to apply to assignments
            args: Command-line arguments (for --skip-pim flag)
        """
        all_assignments = []
        active_permanent_count = 0
        active_timebound_count = 0
        eligible_permanent_count = 0
        eligible_timebound_count = 0
        
        # Determine if we should skip PIM for this scope
        skip_pim = getattr(args, 'skip_pim', False) if args else False
        
        # PIM APIs only work for management groups, subscriptions, and resource groups (not individual resources)
        pim_supported_scope = scope.scope_type in ('Management Group', 'Subscription', 'Resource Group')
        
        if not skip_pim and pim_supported_scope:
            # Try to fetch PIM data (eligible and time-bound active assignments)
            try:
                # Fetch eligible assignments (PIM)
                eligible_data = pim_client.get_eligible_assignments_for_scope(scope)
                
                for eligibility_data in eligible_data:
                    props = eligibility_data.get('properties', {})
                    principal_id = props.get('principalId', '')
                    principal_type = props.get('principalType', 'Unknown')
                    role_def_id = props.get('roleDefinitionId', '')
                    start_date = props.get('startDateTime')
                    end_date = props.get('endDateTime')
                    
                    # Determine if eligible assignment is permanent or time-bound
                    assignment_type = "Eligible time-bound" if end_date else "Eligible permanent"
                    
                    # Get role name
                    role_name = ra_client.get_role_definition(role_def_id)
                    
                    # Get principal name
                    try:
                        principal_name = graph_client.get_principal_display_name(principal_id, principal_type)
                    except Exception:
                        principal_name = principal_id
                    
                    # Create role assignment
                    role_assignment = RoleAssignment(
                        principal_id=principal_id,
                        principal_name=principal_name,
                        principal_type=principal_type,
                        role_name=role_name,
                        role_id=role_def_id,
                        scope=scope.scope_path,
                        scope_name=scope.name,
                        scope_type=scope.scope_type,
                        resource_type=scope.resource_type,
                        assignment_type=assignment_type,
                        start_date_time=start_date,
                        end_date_time=end_date
                    )
                    all_assignments.append(role_assignment)
                    
                    if assignment_type == "Eligible permanent":
                        eligible_permanent_count += 1
                    else:
                        eligible_timebound_count += 1
                
                # Fetch time-bound active assignments (PIM activated)
                timebound_data = pim_client.get_time_bound_active_assignments_for_scope(scope)
                
                for timebound_assignment in timebound_data:
                    props = timebound_assignment.get('properties', {})
                    principal_id = props.get('principalId', '')
                    principal_type = props.get('principalType', 'Unknown')
                    role_def_id = props.get('roleDefinitionId', '')
                    start_date = props.get('startDateTime')
                    end_date = props.get('endDateTime')
                    
                    # Get role name
                    role_name = ra_client.get_role_definition(role_def_id)
                    
                    # Get principal name
                    try:
                        principal_name = graph_client.get_principal_display_name(principal_id, principal_type)
                    except Exception:
                        principal_name = principal_id
                    
                    # Create role assignment (time-bound active)
                    role_assignment = RoleAssignment(
                        principal_id=principal_id,
                        principal_name=principal_name,
                        principal_type=principal_type,
                        role_name=role_name,
                        role_id=role_def_id,
                        scope=scope.scope_path,
                        scope_name=scope.name,
                        scope_type=scope.scope_type,
                        resource_type=scope.resource_type,
                        assignment_type="Active time-bound",
                        start_date_time=start_date,
                        end_date_time=end_date
                    )
                    all_assignments.append(role_assignment)
                    active_timebound_count += 1
                    
            except Exception as e:
                logger.debug(f"PIM API calls failed for {scope.name}: {e}")
        
        # Fetch standard permanent active role assignments
        assignments_data = ra_client.get_direct_assignments_for_scope(scope)
        
        for assignment_data in assignments_data:
            props = assignment_data.get('properties', {})
            principal_id = props.get('principalId', '')
            principal_type = props.get('principalType', 'Unknown')
            role_def_id = props.get('roleDefinitionId', '')
            
            # Get role name
            role_name = ra_client.get_role_definition(role_def_id)
            
            # Get principal name
            try:
                principal_name = graph_client.get_principal_display_name(principal_id, principal_type)
            except Exception:
                principal_name = principal_id
            
            # Create role assignment (Active permanent - standard RBAC)
            role_assignment = RoleAssignment(
                principal_id=principal_id,
                principal_name=principal_name,
                principal_type=principal_type,
                role_name=role_name,
                role_id=role_def_id,
                scope=scope.scope_path,
                scope_name=scope.name,
                scope_type=scope.scope_type,
                resource_type=scope.resource_type,
                assignment_type="Active permanent"
            )
            all_assignments.append(role_assignment)
            active_permanent_count += 1
        
        # Log findings
        if all_assignments:
            # Apply filters if configured
            if assignment_filter and assignment_filter.has_filters():
                filtered_assignments = assignment_filter.apply(all_assignments)
                logger.info(f"{indent}  üìã Found {len(all_assignments)} assignment(s): "
                           f"{active_permanent_count} active permanent, {active_timebound_count} active time-bound, "
                           f"{eligible_permanent_count} eligible permanent, {eligible_timebound_count} eligible time-bound "
                           f"({len(filtered_assignments)} after filtering)")
            else:
                filtered_assignments = all_assignments
                logger.info(f"{indent}  üìã Found {len(filtered_assignments)} assignment(s): "
                           f"{active_permanent_count} active permanent, {active_timebound_count} active time-bound, "
                           f"{eligible_permanent_count} eligible permanent, {eligible_timebound_count} eligible time-bound")
            
            # Add filtered assignments to results
            for assignment in filtered_assignments:
                results.add_assignment(assignment)
        else:
            logger.info(f"{indent}  ‚ö™ No assignments")



def parse_arguments() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description=f"Azure Role Assignment Exporter (ARA) v{__version__} - Export Azure role assignments",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Authentication Methods (tried in order):
  1. --token argument
  2. Environment variables (AZURE_ACCESS_TOKEN, AZURE_TOKEN, ARM_ACCESS_TOKEN)
  3. Azure CLI (az account get-access-token)
  4. macOS Keychain
  5. Interactive prompt

Output:
  Files are generated in the 'results/' directory.
  Console output shows a summary of findings.

Examples:
  # Scan management group (simple format)
  ara --scope my-mg

  # Scan management group (full format)
  ara --scope /providers/Microsoft.Management/managementGroups/my-mg

  # Scan subscription (GUID format)
  ara --scope xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx

  # Scan subscription (full format)
  ara --scope /subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx

  # Include subscriptions (for MG scope)
  ara --scope my-mg --depth subscriptions

  # Scan resource groups in a subscription
  ara --scope xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx --depth resource-groups

  # Export to CSV
  ara --scope my-mg --format csv

  # Export to Excel
  ara --scope my-mg --format xlsx

  # Use specific token
  ara --scope my-mg --token YOUR_TOKEN

  # Debug mode
  ara --scope my-mg --debug
        """
    )
    
    parser.add_argument(
        '--scope',
        required=True,
        help='Scope to scan. Management Group: "my-mg" or full path. Subscription: GUID or "/subscriptions/{guid}"'
    )
    
    parser.add_argument(
        '--token',
        help='Azure access token (overrides auto-detection)'
    )
    
    parser.add_argument(
        '--format',
        choices=['json', 'csv', 'xlsx'],
        default='json',
        help='Output format: json, csv, or xlsx (Excel). Note: xlsx requires openpyxl (pip install openpyxl)'
    )
    
    parser.add_argument(
        '--depth',
        choices=[
            ARAConfig.DEPTH_MANAGEMENT_GROUPS,
            ARAConfig.DEPTH_SUBSCRIPTIONS,
            ARAConfig.DEPTH_RESOURCE_GROUPS,
            ARAConfig.DEPTH_RESOURCES
        ],
        default=ARAConfig.DEFAULT_DEPTH,
        help=f'Scan depth level (default: {ARAConfig.DEFAULT_DEPTH}). '
             'WARNING: resource-groups and resources can be slow for large environments'
    )
    
    parser.add_argument(
        '--resource-types',
        nargs='+',
        help='Filter resources by type (e.g., Microsoft.Compute/virtualMachines). '
             'Only applies when --depth is "resources"'
    )
    
    parser.add_argument(
        '--max-resources',
        type=int,
        default=ARAConfig.DEFAULT_MAX_RESOURCES,
        help=f'Maximum number of resources to scan (default: {ARAConfig.DEFAULT_MAX_RESOURCES}). '
             'Safety limit to prevent runaway scans'
    )
    
    parser.add_argument(
        '--api-delay',
        type=float,
        default=ARAConfig.DEFAULT_API_DELAY,
        help=f'Delay between API calls in seconds (default: {ARAConfig.DEFAULT_API_DELAY}). '
             'Increase to avoid rate limiting'
    )
    
    parser.add_argument(
        '--role-filter',
        type=str,
        help='Filter by role name (comma-separated for multiple). '
             'Example: --role-filter "Owner,Contributor"'
    )
    
    parser.add_argument(
        '--principal-type-filter',
        type=str,
        help='Filter by principal type (comma-separated for multiple). '
             'Valid types: User, Group, ServicePrincipal. '
             'Example: --principal-type-filter "User,Group"'
    )
    
    parser.add_argument(
        '--principal-name-filter',
        type=str,
        help='Filter by principal name (supports regex patterns). '
             'Example: --principal-name-filter "^Admin.*"'
    )
    
    parser.add_argument(
        '--exclude-system',
        action='store_true',
        help='Exclude system-assigned managed identities from results'
    )
    
    parser.add_argument(
        '--assignment-type-filter',
        type=str,
        help='Filter by assignment type (comma-separated for multiple). '
             'Valid types: "Active permanent", "Active time-bound", "Eligible permanent", "Eligible time-bound". '
             'Example: --assignment-type-filter "Active permanent,Eligible permanent"'
    )
    
    parser.add_argument(
        '--skip-pim',
        action='store_true',
        help='Skip PIM (Privileged Identity Management) API calls. '
             'Use this if PIM is not enabled or to improve performance.'
    )
    
    parser.add_argument(
        '--debug',
        action='store_true',
        help='Enable debug output'
    )
    
    parser.add_argument(
        '--no-progress',
        action='store_true',
        help='Disable progress bar display'
    )
    
    parser.add_argument(
        '--version',
        action='version',
        version=f'ARA v{__version__}'
    )
    
    return parser.parse_args()


def main() -> int:
    """Main application entry point."""
    # Ignore SIGPIPE to prevent broken pipe errors
    signal.signal(signal.SIGPIPE, signal.SIG_DFL)
    
    args = parse_arguments()
    
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Create results directory relative to script location
    script_dir = os.path.dirname(os.path.abspath(__file__))
    results_dir = os.path.join(script_dir, ARAConfig.RESULTS_DIR)
    
    app = ARAApplication(results_dir)
    try:
        return app.run(args)
    except BrokenPipeError:
        try:
            sys.stdout.close()
        except OSError:
            pass
        try:
            sys.stderr.close()
        except OSError:
            pass
        return ARAConfig.EXIT_CODE_SUCCESS


if __name__ == "__main__":
    sys.exit(main())
